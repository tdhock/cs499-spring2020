Coding project 3: neural network for binary classification.

For this project you will be implementing a stochastic gradient
descent algorithm for a neural network with one hidden layer.

For this project it is strongly encouraged to use R packages
data.table and ggplot2 for data reading and visualization,
[[file:3.R][See example/demo R script]].

** Algorithm: stochastic gradient descent with early stopping regularization
Function name: NNetOneSplit
- (10 points) Inputs should be: 
  - X.mat (train inputs/feature matrix, n_observations x n_features), 
  - y.vec (train outputs/label vector, n_observations x 1), 
  - max.epochs (int scalar > 1),
  - step.size (double scalar > 0), 
  - n.hidden.units (int scalar>1, number of hidden units), 
  - is.subtrain (logical vector, size n_observations)
- (10 points) begin by dividing X.mat/y.vec into
  X.subtrain/X.validation/y.subtrain/y.validation using is.subtrain -- subtrain set is for computing gradients, validation set is for choosing the optimal number of steps (with minimal loss).
- (10 points) the algorithm should initialize V.mat/w.vec to some random numbers
  close to zero (e.g. using rnorm in R). 
  - V.mat is a weight matrix (n_features x n.hidden.units), used to
    predict hidden units given inputs.
  - w.vec is a weight vector (n.hidden.units), used to predict output
    given hidden units.
- (10 points) There should be a for loop over epochs from k=1 to
  max.epochs. Each epoch is a single pass through the subtrain set. In
  other words, in each epoch, you will update the parameters using the
  gradients with respect to each subtrain observation.
- (10 points) for each epoch there should be a for loop over data
  points in the subtrain set. During each iteration of this inner loop you
  should compute the gradients of V.mat/w.vec with respect to a
  a single observation in the subtrain set, then update
  V.mat/w.vec by taking a step (scaled by step.size) in the negative
  gradient direction.
- (10 points) the last thing you should do during each epoch is, after
  having gone through all the data points in the subtrain set, compute
  the logistic loss on the subtrain/validation sets, and store those
  in a variable called loss.values. Remember the logistic loss is:
  log[1+exp(-yf(x))] where y is a label in {-1,1} and f(x) is a real-valued prediction.
- (10 points) Outputs should be a list/dictionary/etc with at least three named elements:
  - loss.values, a matrix/data.table/etc which stores the logistic
    loss with respect to the subtrain/validation set for each epoch.
  - V.mat, the weight matrix after having done gradient descent for
    the specified number of epochs (max.epochs).
  - w.vec, the weight vector after having done gradient descent for
    the specified number of epochs (max.epochs).

** Experiments/application

- Use spam data set from
  [[https://web.stanford.edu/~hastie/ElemStatLearn/data.html]]
- First scale the input matrix (each column should have
  mean 0 and variance 1). You can do this by subtracting away the mean
  and then dividing by the standard deviation of each column (or just
  use a standard function like scale in R).
- (5 points) Next create a variable is.train (logical vector with size
  equal to the number of observations in the whole data set). Each
  element is TRUE if the corresponding observation (row of input
  matrix) is in the train set, and FALSE otherwise. There should be
  80% train, 20% test observations (out of all observations in the
  whole data set).
- (5 points) Next create a variable is.subtrain (logical vector with
  size equal to the number of observations in the train set). Each
  element is TRUE if the corresponding observation is is the subtrain
  set, and FALSE otherwise. There should be 60% subtrain, 40%
  validation observations (out of 100% train observations).
- (5 points) Use NNetOneSplit with the train set as X.mat/y.vec, with
  is.subtrain as specified above, and a large number for max.epochs.
- (5 points) Plot the subtrain/validation loss as a function of the
  number of epochs, and draw a point to emphasize the minimum of
  the validation loss curve. 
- (5 points) Define a variable called best_epochs which is the number
  of epochs which minimizes the validation loss. Use NNetOneSplit with
  the train set as X.mat/y.vec, but this time use is.subtrain=TRUE for
  all observations, and use max.epochs=best_epochs.
- (5 points) Finally use the learned V.mat/w.vec to make predictions
  on the test set. What is the prediction accuracy? (percent correctly
  predicted labels in the test set) What is the prediction accuracy of
  the baseline model which predicts the most frequent class in the
  train labels? 

*** Grading rubric 

Your final grade for this project will be computed by multiplying the
percentage from your [[file:group-evals.org][group evaluations]] with your group's total score
from the rubric above.

Your group should submit a PDF on BBLearn. 
- The first thing in the PDF should be your names and student ID's
  (e.g. th798) and a link to your source code in a public repo
  (e.g. github, there should be no code in your PDF report).
- The second thing in the PDF should be your group evaluation scores
  for yourself and your teammates.

Extra credit: 
- 10 points if your github repo includes a README.org (or README.md
  etc) file with a link to the source code of your NNOneSplit
  function, and an explanation about how to run it on the data sets.
- 10 points if you do 4-fold cross-validation instead of the single
  train/test split described above, and you make a plot of accuracy
  for both models for each split/fold.
- 10 points if you show GradientDescent (from project 1, logistic regression with
  number of iterations selected by a held-out validation set) in your
  test accuracy result figure.
- 10 points if you show NearestNeighborsCV (from project 2) in your
  test accuracy figure.
- 10 points if you compute and plot ROC curves for each (test fold,
  algorithm) combination. Make sure each algorithm is drawn in a
  different color, and there is a legend that the reader can use to
  read the figure. Example:

[[file:1-ROC.PNG]]
  
- 10 points if you compute area under the ROC curve (AUC) and include
  that as another evaluation metric (in a separate panel/plot) to
  compare the test accuracy of the algorithms.
  
** FAQ

- how to debug R code? you should use traceback() to find out where
  the error is happening, the put print statements or browser() on the
  line just before the error, so you can see what is going on and
  debug.
- for making data tables to visualize using ggplot2 you may want to
  use [[http://members.cbio.mines-paristech.fr/~thocking/animint2-manual/Ch17-appendix.html#list-of-data-tables][the list of data tables idiom]].
